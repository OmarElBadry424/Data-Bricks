
Initialization

import pyspark.sql.functions as F
from pyspark.sql.types import StringType
from pyspark.sql.functions import trim, col
     
Read Bronze table

df = spark.table("workspace.bronze.erp_px_cat_g1v2")
     
Silver Transformations
Trimming

for field in df.schema.fields:
    if isinstance(field.dataType, StringType):
        df = df.withColumn(field.name, trim(col(field.name)))
     
Normalize Maintenance Flag to Boolean

df = df.withColumn(
    "maintenance",
    F.when(F.upper(col("maintenance")) == "YES", F.lit(True))
     .when(F.upper(col("maintenance")) == "NO", F.lit(False))
     .otherwise(None)
)

     
Renaming Columns

RENAME_MAP = {
    "id": "category_id",
    "cat": "category",
    "subcat": "subcategory",
    "maintenance": "maintenance_flag"
}
for old_name, new_name in RENAME_MAP.items():
    df = df.withColumnRenamed(old_name, new_name)
     
Sanity checks of dataframe

df.limit(10).display()
     
Writing Silver Table

df.write.mode("overwrite").format("delta").saveAsTable("workspace.silver.erp_product_category")
     
Sanity checks of silver table

%sql
SELECT * FROM workspace.silver.erp_product_category LIMIT 10
     
